
# Exploratory Data Analysis

EDA is the process of examining and analyzing data sets to summarize their main characteristics, often using visual methods. The goal of EDA is to gain insights and understanding of the data, identify patterns and relationships, and generate hypotheses for further investigation. EDA is typically performed at the beginning of a data analysis project, before any formal modeling or hypothesis testing is carried out.

Techniques used in EDA include:

Data visualization: using plots, charts, and graphs to visualize the data, such as scatterplots, histograms, and boxplots.

Descriptive statistics: calculating summary statistics such as mean, median, standard deviation, and correlation coefficients to describe the central tendency, dispersion, and relationships between variables.

Data cleaning and preprocessing: identifying and correcting errors, missing values, and outliers in the data to ensure its quality and consistency.

Dimensionality reduction: reducing the number of variables in the data to simplify the analysis and highlight important features.

Pattern recognition: identifying trends, clusters, and anomalies in the data to reveal underlying patterns and relationships.

EDA performed by me on the datasets are:

1.EDA With Red Wine Data:

About Dataset:
The two datasets are related to red and white variants of the Portuguese "Vinho Verde" wine. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).

These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.

2.EDA Student Performance Indicator
Problem statement
This project understands how the student's performance (test scores) is affected by other variables such as Gender, Ethnicity, Parental level of education, Lunch and Test preparation course.

3.Algerian Forest Fires from UCI. 
The dataset contains a culmination of forest fire observations and data in two regions of Algeria: the Bejaia region and the Sidi Bel-Abbes region. The timeline of this dataset is from June 2012 to September 2012. In this project, we focused on whether certain weather features could predict forest fires in these regions using few Classification algorithms.
In this step, we will apply Exploratory Data Analysis (EDA) to extract insights from the data set to know which features have contributed more in predicting Forest fire by performing Data Analysis using Pandas and Data visualization using Matplotlib & Seaborn. It is always a good practice to understand the data first and try to gather as many insights from it.

4.IPL DATASET:
Collected IPL dataset from reliable sources such as Kaggle.

Data Cleaning: Once have the data, the next step is to clean the dataset by removing missing values, duplicates, and inconsistent data.

Data Exploration: After cleaning the dataset, the next step is to explore the data to get a better understanding of the data. You can use techniques such as data visualization, summary statistics, and correlation analysis to understand the data better. For instance, you can create bar charts to understand the distribution of runs scored by players, scatterplots to visualize the relationship between the strike rate and the number of boundaries scored, etc.

Data Analysis: Once have explored the data, the next step is to perform analysis on the dataset. You can use statistical methods such as hypothesis testing, regression analysis, clustering, and machine learning to analyze the data.

Draw Conclusions: Finally, can draw conclusions based on the analysis performed on the dataset. Can create reports or visualizations to communicate the findings and insights with others.

5.Literacy Dataset:
Collected the literacy data from reliable sources such as UNESCO, World Bank, or government statistics websites.

Data Cleaning: Once have the data, the next step is to clean the dataset by removing missing values, duplicates, and inconsistent data.

Data Exploration: After cleaning the dataset, the next step is to explore the data to get a better understanding of the data.Used techniques such as data visualization, summary statistics, and correlation analysis to understand the data better. For instance, you can create bar charts to understand the distribution of literacy rates across different countries, scatterplots to visualize the relationship between literacy rates and economic development, etc.

Data Analysis:Explored the data, the next step is to perform analysis on the dataset.Can use statistical methods such as hypothesis testing, regression analysis, clustering, and machine learning to analyze the data.

Draw Conclusions: Finally, can draw conclusions based on the analysis performed on the dataset. Can create reports or visualizations to communicate the findings and insights with others.


## Demo

https://miro.medium.com/v2/1*Owa2rsDG6Rwv1IM_RdsL3A.gif

